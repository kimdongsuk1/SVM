{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "data = np.genfromtxt('creditcard.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284808, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "redata=data[1:,1:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(redata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalabel=df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=datalabel.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RepeatedKFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X11 = redata[label==0]\n",
    "X22 = redata[label==1]\n",
    "\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=50, n_repeats=2, random_state=3) \n",
    "\n",
    "for train_index, test_index in rkf.split(X11):\n",
    "    X_train1, X_test1 = X11[train_index], X11[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5686, 29)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rkf = RepeatedKFold(n_splits=10, n_repeats=1, random_state=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(object):\n",
    "    \n",
    "    def __init__(self, kernel=linear_kernel, C=None):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        if self.C is not None: self.C = float(self.C)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = np.shape(X)\n",
    "        \n",
    "        # Gram matrix\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                K[i,j] = self.kernel(X[i], X[j])\n",
    "        \n",
    "        P = cvxopt.matrix(np.outer(y,y) * K) # can be singular \n",
    "        \n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        \n",
    "        # label Vector\n",
    "        \n",
    "        A = cvxopt.matrix(y, (1,n_samples)) \n",
    "        \n",
    "        b = cvxopt.matrix(0.0)\n",
    "        \n",
    "        if self.C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "        else: # kernel is nontrivial.\n",
    "            tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "            tmp2 = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * self.C\n",
    "            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "\n",
    "        # solve QP problem\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        # Lagrange multipliers\n",
    "        a = np.ravel(solution['x'])\n",
    "\n",
    "        # Support vectors have non zero lagrange multipliers\n",
    "        sv = a > 1e-5\n",
    "        ind = np.arange(len(a))[sv]\n",
    "        self.a = a[sv]\n",
    "        self.sv = X[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        print('{0} support vectors out of {1} points'.format(len(self.a), n_samples))\n",
    "\n",
    "        # Intercept\n",
    "        self.b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            self.b += self.sv_y[n]\n",
    "            self.b -= np.sum(self.a * self.sv_y * K[ind[n],sv])\n",
    "        self.b /= len(self.a)\n",
    "\n",
    "        # Weight vector\n",
    "        if self.kernel == linear_kernel:\n",
    "            self.w = np.zeros(n_features)\n",
    "            for n in range(len(self.a)):\n",
    "                self.w += self.a[n] * self.sv_y[n] * self.sv[n]\n",
    "        else:\n",
    "            self.w = None\n",
    "    \n",
    "    def project(self, X):\n",
    "        if self.w is not None:\n",
    "            return np.dot(X, self.w) + self.b\n",
    "        else:\n",
    "            y_predict = np.zeros(len(X))\n",
    "            for i in range(len(X)):\n",
    "                s = 0\n",
    "                for a, sv_y, sv in zip(self.a, self.sv_y, self.sv):\n",
    "                    s += a * sv_y * self.kernel(X[i], sv)\n",
    "                y_predict[i] = s\n",
    "        return y_predict + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.project(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization problem of SVM can be rewrite as dual problem :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\max_{\\alpha} \\sum_i^m \\alpha_i - \\frac{1}{2} \\sum_{i,j}^m y^{(i)}y^{(j)} \\alpha_i \\alpha_j <x^{(i)} x^{(j)}>$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under condition : \n",
    "$\\begin{aligned}\n",
    "& \\max_{\\alpha} \\sum_i^m \\alpha_i  - \\frac{1}{2}  \\alpha^T \\mathbf{H}  \\alpha\n",
    "\\\\\n",
    " s.t. & \\ \\alpha_i \\geq 0 \n",
    "\\\\\n",
    "&  \\ \\sum_i^m \\alpha_i y^{(i)} = 0  \n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Implement SVM on three nonlinear kernel : Gaussian,Polynomial,Sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datas are very large. In particular ratio of two labeled datas is very big. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway cost time is highly required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we only use the data with rabel 0 about 1 percent and 8 principal component of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each kernel, we try to search suited hyperparameter.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The  key strategy is Random Cross validation for each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We select one optimal svm from 9 candidate for each kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import matplotlib.pyplot as pl\n",
    "    \n",
    "    \n",
    "    def gen_non_lin_separable_data():\n",
    "        X22 = redata[label==1]\n",
    "        \n",
    "            \n",
    "    \n",
    "        X1 = X_test1\n",
    "        X2 = X22\n",
    "        y1 = np.ones(len(X_test1))\n",
    "        y2 = np.ones(len(X2)) * -1\n",
    "        \n",
    "        return X1, y1, X2, y2\n",
    "\n",
    "    def split_train(X1, y1, X2, y2,i):\n",
    "        \n",
    "\n",
    "        rrkf = RepeatedKFold(n_splits=10, n_repeats=3, random_state=i) \n",
    "\n",
    "\n",
    "        for train_index, test_index in rrkf.split(X1):\n",
    "            Xtrain1, Xtest1= X1[train_index], X1[test_index]\n",
    "\n",
    "\n",
    "        for train_index, test_index in rrkf.split(X2):\n",
    "            Xtrain2, Xtest2= X2[train_index], X2[test_index]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        X1_train = Xtrain1[:,:8]\n",
    "        y1_train = y1[:len(Xtrain1)]\n",
    "        X2_train = Xtrain2[:,:8]\n",
    "        y2_train = y2[:len(Xtrain2)]\n",
    "        X_train = np.vstack((X1_train, X2_train))\n",
    "        y_train = np.hstack((y1_train, y2_train))\n",
    "        \n",
    "        X1_test = Xtest1[:,:8]\n",
    "        y1_test = y1[:len(Xtest1)]\n",
    "        X2_test = Xtest2[:,:8]\n",
    "        y2_test = y2[:len(Xtest2)]\n",
    "        X_test = np.vstack((X1_test, X2_test))\n",
    "        y_test = np.hstack((y1_test, y2_test))\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    \n",
    "    \n",
    "    def plot_contour(X1_train, X2_train, clf):\n",
    "        pl.plot(X1_train[:100,0], X1_train[:100,1],\"ro\",ms=2)\n",
    "        pl.plot(X2_train[:100,0], X2_train[:100,1],\"bo\",ms=2)\n",
    "        pl.scatter(clf.sv[:100,0], clf.sv[:100,1], s=10, c=\"g\")\n",
    "        \n",
    "        X1, X2 = np.meshgrid(np.linspace(-10,10,500), np.linspace(-10,10,500))\n",
    "        X = np.array([[x1, x2,0,0,0,0,0,0] for x1, x2 in zip(np.ravel(X1), np.ravel(X2))])\n",
    "        Z1 = clf.project(X)\n",
    "        Z=Z1.reshape(X1.shape)\n",
    "        pl.contour(X1, X2, Z, [0.0], colors='k', linewidths=1, origin='lower')\n",
    "        pl.contour(X1, X2, Z + 1, [0.0], colors='grey', linewidths=1, origin='lower')\n",
    "        pl.contour(X1, X2, Z - 1, [0.0], colors='grey', linewidths=1, origin='lower')\n",
    "        \n",
    "        pl.axis(\"tight\")\n",
    "        pl.show()\n",
    "    \n",
    "    def test_non_linear1():\n",
    "        \n",
    "        X1, y1, X2, y2 = gen_non_lin_separable_data()\n",
    "        \n",
    "        for i in range(1,10):\n",
    "\n",
    "\n",
    "            def gaussian_kernel(x, y, sigma=i+3):\n",
    "                return np.exp(-linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "            X_train, y_train, X_test, y_test = split_train(X1, y1, X2, y2,i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            clf = SVM(gaussian_kernel)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            y_predict = clf.predict(X_test)\n",
    "            correct = np.sum(y_predict == y_test)\n",
    "            print('{0} out of {1} predictions correct'.format(correct, len(y_predict)))\n",
    "\n",
    "        #plot_contour(X_train[y_train==1], X_train[y_train==-1], clf)\n",
    "\n",
    "\n",
    "    def test_non_linear11():\n",
    "        \n",
    "        X1, y1, X2, y2 = gen_non_lin_separable_data()\n",
    "        \n",
    "        def gaussian_kernel(x, y, sigma=6):\n",
    "                return np.exp(-linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "        X_train, y_train, X_test, y_test = split_train(X1, y1, X2, y2,6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        clf = SVM(gaussian_kernel)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_predict = clf.predict(X_test)\n",
    "        correct = np.sum(y_predict == y_test)\n",
    "        print('{0} out of {1} predictions correct'.format(correct, len(y_predict)))\n",
    "        \n",
    "        plot_contour(X_train[y_train==1], X_train[y_train==-1], clf)\n",
    "\n",
    "    #test_non_linear1()\n",
    "    #test_non_linear2()\n",
    "    #test_non_linear3()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large Set\\ Optimal\\ parameter\\ for\\ gaussian\\ as\\ sigma=6\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large Plotting\\ 2\\ principal\\ component\\ parts\\ and\\ margin(Gaussian\\ kernel).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.3355e+02 -1.0972e+03  1e+04  8e+01  3e+00\n",
      " 1: -1.1584e+03 -3.1834e+03  1e+04  6e+01  3e+00\n",
      " 2: -4.0089e+03 -9.4922e+03  1e+04  5e+01  2e+00\n",
      " 3: -8.5590e+03 -1.5693e+04  1e+04  4e+01  2e+00\n",
      " 4: -1.6815e+04 -2.6165e+04  1e+04  4e+01  1e+00\n",
      " 5: -3.4211e+04 -4.7006e+04  2e+04  3e+01  1e+00\n",
      " 6: -8.4975e+04 -1.0453e+05  2e+04  3e+01  1e+00\n",
      " 7: -1.7687e+05 -2.0707e+05  3e+04  3e+01  1e+00\n",
      " 8: -4.0894e+05 -4.6275e+05  6e+04  3e+01  1e+00\n",
      " 9: -7.8081e+05 -8.6882e+05  9e+04  3e+01  1e+00\n",
      "10: -1.3039e+06 -1.4383e+06  1e+05  3e+01  1e+00\n",
      "11: -2.5119e+06 -2.7506e+06  2e+05  3e+01  1e+00\n",
      "12: -3.5629e+06 -3.8858e+06  3e+05  3e+01  1e+00\n",
      "13: -6.6417e+06 -7.1978e+06  6e+05  3e+01  1e+00\n",
      "14: -9.5466e+06 -1.0305e+07  8e+05  3e+01  1e+00\n",
      "15: -1.3868e+07 -1.4924e+07  1e+06  3e+01  1e+00\n",
      "16: -2.3347e+07 -2.5098e+07  2e+06  3e+01  1e+00\n",
      "17: -3.0540e+07 -3.2900e+07  2e+06  3e+01  1e+00\n",
      "18: -4.7551e+07 -5.1656e+07  4e+06  3e+01  1e+00\n",
      "19: -7.0039e+07 -7.7138e+07  7e+06  3e+01  1e+00\n",
      "20: -1.2565e+08 -1.4318e+08  2e+07  2e+01  1e+00\n",
      "21: -2.2957e+08 -2.7695e+08  5e+07  2e+01  9e-01\n",
      "22: -3.9113e+08 -4.9528e+08  1e+08  1e+01  6e-01\n",
      "23: -4.6103e+08 -5.1575e+08  5e+07  4e+00  2e-01\n",
      "24: -4.6379e+08 -4.7000e+08  6e+06  1e-02  5e-04\n",
      "25: -4.6655e+08 -4.6914e+08  3e+06  5e-03  2e-04\n",
      "26: -4.6810e+08 -4.6872e+08  6e+05  3e-05  1e-06\n",
      "27: -4.6859e+08 -4.6868e+08  8e+04  1e-06  2e-07\n",
      "28: -4.6866e+08 -4.6867e+08  6e+03  9e-08  2e-07\n",
      "29: -4.6867e+08 -4.6867e+08  9e+01  2e-07  2e-07\n",
      "30: -4.6867e+08 -4.6867e+08  1e+00  2e-07  2e-07\n",
      "31: -4.6867e+08 -4.6867e+08  1e-02  7e-07  3e-07\n",
      "32: -4.6867e+08 -4.6867e+08  1e-04  2e-06  5e-07\n",
      "33: -4.6867e+08 -4.6867e+08  1e-06  1e-06  5e-07\n",
      "34: -4.6867e+08 -4.6867e+08  2e-08  6e-08  1e-07\n",
      "35: -4.6867e+08 -4.6867e+08  2e-08  2e-07  8e-08\n",
      "36: -4.6867e+08 -4.6867e+08  2e-10  2e-07  9e-08\n",
      "Terminated (singular KKT matrix).\n",
      "235 support vectors out of 3002 points\n",
      "314 out of 333 predictions correct\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def test_non_linear11():\n",
    "\n",
    "    X1, y1, X2, y2 = gen_non_lin_separable_data()\n",
    "\n",
    "    def gaussian_kernel(x, y, sigma=6):\n",
    "            return np.exp(-linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "    X_train, y_train, X_test, y_test = split_train(X1, y1, X2, y2,6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    clf = SVM(gaussian_kernel)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_predict = clf.predict(X_test)\n",
    "    correct = np.sum(y_predict == y_test)\n",
    "    print('{0} out of {1} predictions correct'.format(correct, len(y_predict)))\n",
    "\n",
    "    plot_contour(X_train[y_train==1], X_train[y_train==-1], clf)\n",
    "test_non_linear11()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.6762e+02 -1.4739e+03  2e+04  1e+02  3e+00\n",
      " 1: -1.3954e+03 -3.7898e+03  2e+04  1e+02  3e+00\n",
      " 2: -4.1897e+03 -1.0552e+04  2e+04  9e+01  3e+00\n",
      " 3: -9.0326e+03 -1.8430e+04  2e+04  7e+01  2e+00\n",
      " 4: -1.4842e+04 -2.7171e+04  2e+04  7e+01  2e+00\n",
      " 5: -2.5503e+04 -4.0859e+04  2e+04  6e+01  2e+00\n",
      " 6: -3.4088e+04 -5.2276e+04  2e+04  5e+01  2e+00\n",
      " 7: -4.8159e+04 -7.0154e+04  3e+04  5e+01  1e+00\n",
      " 8: -7.7840e+04 -1.0685e+05  3e+04  5e+01  1e+00\n",
      " 9: -9.9471e+04 -1.3389e+05  4e+04  5e+01  1e+00\n",
      "10: -2.2173e+05 -2.7498e+05  6e+04  4e+01  1e+00\n",
      "11: -4.5695e+05 -5.4464e+05  9e+04  4e+01  1e+00\n",
      "12: -1.3964e+06 -1.5759e+06  2e+05  4e+01  1e+00\n",
      "13: -3.8942e+06 -4.2918e+06  4e+05  4e+01  1e+00\n",
      "14: -9.7093e+06 -1.0562e+07  9e+05  4e+01  1e+00\n",
      "15: -1.0021e+08 -1.0235e+08  2e+06  4e+01  1e+00\n",
      "16: -3.1088e+09 -3.1335e+09  2e+07  4e+01  1e+00\n",
      "17: -4.0998e+10 -4.1293e+10  3e+08  4e+01  1e+00\n",
      "18: -4.1772e+10 -4.2073e+10  3e+08  4e+01  1e+00\n",
      "19: -4.3213e+10 -4.3523e+10  3e+08  4e+01  1e+00\n",
      "20: -4.5232e+10 -4.5555e+10  3e+08  4e+01  1e+00\n",
      "21: -5.1185e+10 -5.1549e+10  4e+08  4e+01  1e+00\n",
      "22: -5.3636e+10 -5.4014e+10  4e+08  4e+01  1e+00\n",
      "23: -5.7082e+10 -5.7484e+10  4e+08  4e+01  1e+00\n",
      "Terminated (singular KKT matrix).\n",
      "3002 support vectors out of 3002 points\n",
      "284 out of 333 predictions correct\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.3278e+02 -1.0310e+03  2e+04  1e+02  3e+00\n",
      " 1: -1.1627e+03 -3.0284e+03  2e+04  9e+01  3e+00\n",
      " 2: -3.4745e+03 -8.1723e+03  2e+04  8e+01  2e+00\n",
      " 3: -7.2742e+03 -1.4000e+04  2e+04  6e+01  2e+00\n",
      " 4: -1.2229e+04 -2.0552e+04  2e+04  6e+01  2e+00\n",
      " 5: -1.9002e+04 -2.9025e+04  2e+04  5e+01  2e+00\n",
      " 6: -2.9795e+04 -4.2288e+04  2e+04  5e+01  1e+00\n",
      " 7: -4.6683e+04 -6.2712e+04  2e+04  4e+01  1e+00\n",
      " 8: -6.9174e+04 -8.9886e+04  3e+04  4e+01  1e+00\n",
      " 9: -1.1316e+05 -1.4223e+05  4e+04  4e+01  1e+00\n",
      "10: -1.2429e+05 -1.5549e+05  4e+04  4e+01  1e+00\n",
      "11: -1.8872e+05 -2.3107e+05  5e+04  4e+01  1e+00\n",
      "12: -2.7545e+05 -3.3205e+05  6e+04  4e+01  1e+00\n",
      "13: -3.4290e+05 -4.1031e+05  8e+04  4e+01  1e+00\n",
      "14: -4.1063e+05 -4.8853e+05  9e+04  4e+01  1e+00\n",
      "15: -4.7621e+05 -5.6392e+05  1e+05  4e+01  1e+00\n",
      "16: -5.5702e+05 -6.5653e+05  1e+05  4e+01  1e+00\n",
      "17: -6.7069e+05 -7.8638e+05  1e+05  4e+01  1e+00\n",
      "18: -7.7115e+05 -9.0080e+05  1e+05  4e+01  1e+00\n",
      "19: -9.7198e+05 -1.1283e+06  2e+05  4e+01  1e+00\n",
      "20: -1.1597e+06 -1.3407e+06  2e+05  4e+01  1e+00\n",
      "21: -1.3687e+06 -1.5763e+06  2e+05  4e+01  1e+00\n",
      "22: -1.9029e+06 -2.1749e+06  3e+05  4e+01  1e+00\n",
      "23: -2.0436e+06 -2.3328e+06  3e+05  4e+01  1e+00\n",
      "24: -2.5371e+06 -2.8847e+06  4e+05  4e+01  1e+00\n",
      "25: -3.3331e+06 -3.7713e+06  5e+05  4e+01  1e+00\n",
      "26: -4.9982e+06 -5.6141e+06  7e+05  4e+01  1e+00\n",
      "27: -6.5403e+06 -7.3178e+06  8e+05  4e+01  1e+00\n",
      "28: -7.4247e+06 -8.2943e+06  9e+05  4e+01  1e+00\n",
      "29: -8.9091e+06 -9.9297e+06  1e+06  4e+01  1e+00\n",
      "30: -1.1459e+07 -1.2730e+07  1e+06  4e+01  1e+00\n",
      "31: -1.3585e+07 -1.5062e+07  2e+06  4e+01  1e+00\n",
      "32: -1.8521e+07 -2.0457e+07  2e+06  4e+01  1e+00\n",
      "33: -2.0586e+07 -2.2713e+07  2e+06  4e+01  1e+00\n",
      "34: -3.1912e+07 -3.5033e+07  3e+06  4e+01  1e+00\n",
      "35: -5.4415e+07 -5.9399e+07  5e+06  4e+01  1e+00\n",
      "36: -5.7316e+07 -6.2542e+07  5e+06  4e+01  1e+00\n",
      "37: -6.5757e+07 -7.1679e+07  6e+06  4e+01  1e+00\n",
      "38: -8.2461e+07 -8.9730e+07  7e+06  4e+01  1e+00\n",
      "39: -8.3288e+07 -9.0623e+07  7e+06  4e+01  1e+00\n",
      "40: -2.3577e+08 -2.5347e+08  2e+07  4e+01  1e+00\n",
      "41: -4.2619e+08 -4.5638e+08  3e+07  4e+01  1e+00\n",
      "42: -1.0630e+09 -1.1309e+09  7e+07  4e+01  1e+00\n",
      "43: -2.0053e+09 -2.1265e+09  1e+08  4e+01  1e+00\n",
      "44: -1.8146e+10 -1.8740e+10  6e+08  3e+01  1e+00\n",
      "45: -3.1586e+10 -3.2598e+10  1e+09  3e+01  1e+00\n",
      "46: -5.5939e+10 -5.7671e+10  2e+09  3e+01  1e+00\n",
      "47: -1.1227e+11 -1.1559e+11  3e+09  3e+01  1e+00\n",
      "48: -1.7704e+11 -1.8203e+11  5e+09  3e+01  1e+00\n",
      "49: -2.0056e+11 -2.0593e+11  5e+09  3e+01  1e+00\n",
      "50: -2.0484e+11 -2.1022e+11  5e+09  3e+01  1e+00\n",
      "Terminated (singular KKT matrix).\n",
      "3002 support vectors out of 3002 points\n",
      "301 out of 333 predictions correct\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0993e+02 -6.3507e+02  2e+04  9e+01  3e+00\n",
      " 1: -8.4098e+02 -2.0382e+03  1e+04  7e+01  2e+00\n",
      " 2: -2.1280e+03 -4.2305e+03  1e+04  6e+01  2e+00\n",
      " 3: -3.1546e+03 -5.3692e+03  1e+04  5e+01  2e+00\n",
      " 4: -5.1765e+03 -7.4599e+03  1e+04  4e+01  1e+00\n",
      " 5: -8.0625e+03 -1.0276e+04  1e+04  4e+01  1e+00\n",
      " 6: -1.0824e+04 -1.2953e+04  1e+04  4e+01  1e+00\n",
      " 7: -1.3656e+04 -1.5557e+04  1e+04  3e+01  1e+00\n",
      " 8: -1.9052e+04 -2.0189e+04  2e+04  3e+01  1e+00\n",
      " 9: -2.4565e+04 -2.5451e+04  2e+04  3e+01  1e+00\n",
      "10: -3.1892e+04 -3.1642e+04  2e+04  3e+01  1e+00\n",
      "11: -3.2130e+04 -3.0024e+04  2e+04  3e+01  9e-01\n",
      "12: -2.7959e+04 -2.2431e+04  3e+04  2e+01  8e-01\n",
      "13: -1.6130e+04 -8.6478e+03  3e+04  1e+01  5e-01\n",
      "14: -8.6633e+03 -3.4514e+03  2e+04  8e+00  3e-01\n",
      "15: -6.0328e+03 -2.2646e+03  2e+04  6e+00  2e-01\n",
      "16: -2.7718e+03 -1.1031e+03  8e+03  3e+00  1e-01\n",
      "17: -1.5034e+03 -7.8071e+02  6e+03  2e+00  6e-02\n",
      "18: -9.8643e+02 -6.3799e+02  4e+03  1e+00  4e-02\n",
      "19: -4.5460e+02 -4.6285e+02  2e+03  5e-01  2e-02\n",
      "20: -2.7792e+02 -3.7536e+02  2e+03  3e-01  1e-02\n",
      "21: -1.6857e+02 -2.8533e+02  9e+02  1e-01  5e-03\n",
      "22: -1.1418e+02 -2.5423e+02  7e+02  9e-02  3e-03\n",
      "23: -1.0284e+02 -2.0641e+02  4e+02  5e-02  2e-03\n",
      "24: -8.5016e+01 -1.7367e+02  3e+02  3e-02  9e-04\n",
      "25: -7.6584e+01 -1.5795e+02  2e+02  2e-02  6e-04\n",
      "26: -8.0441e+01 -1.3281e+02  2e+02  1e-02  3e-04\n",
      "27: -7.6295e+01 -1.1955e+02  1e+02  6e-03  2e-04\n",
      "28: -7.3471e+01 -1.1228e+02  1e+02  4e-03  1e-04\n",
      "29: -7.4712e+01 -1.0328e+02  7e+01  3e-03  9e-05\n",
      "30: -7.6748e+01 -9.5592e+01  5e+01  2e-03  6e-05\n",
      "31: -7.5661e+01 -9.2489e+01  4e+01  1e-03  4e-05\n",
      "32: -7.3042e+01 -9.0397e+01  4e+01  9e-04  3e-05\n",
      "33: -7.1746e+01 -8.9705e+01  4e+01  8e-04  3e-05\n",
      "34: -7.5213e+01 -8.5775e+01  2e+01  4e-04  1e-05\n",
      "35: -7.5075e+01 -8.4728e+01  2e+01  3e-04  9e-06\n",
      "36: -7.5757e+01 -8.3452e+01  1e+01  2e-04  5e-06\n",
      "37: -7.5813e+01 -8.3025e+01  1e+01  1e-04  4e-06\n",
      "38: -7.5272e+01 -8.2489e+01  1e+01  9e-05  3e-06\n",
      "39: -7.5255e+01 -8.1744e+01  1e+01  6e-05  2e-06\n",
      "40: -7.5338e+01 -8.1250e+01  9e+00  5e-05  2e-06\n",
      "41: -7.5452e+01 -8.0685e+01  9e+00  4e-05  1e-06\n",
      "42: -7.5203e+01 -8.0078e+01  8e+00  3e-05  1e-06\n",
      "43: -7.5153e+01 -7.9919e+01  8e+00  3e-05  1e-06\n",
      "44: -7.5189e+01 -7.9613e+01  8e+00  3e-05  1e-06\n",
      "45: -7.5350e+01 -7.9106e+01  7e+00  2e-05  8e-07\n",
      "46: -7.5292e+01 -7.8481e+01  7e+00  2e-05  6e-07\n",
      "47: -7.5379e+01 -7.8047e+01  6e+00  1e-05  5e-07\n",
      "48: -7.4654e+01 -7.7563e+01  6e+00  1e-05  3e-07\n",
      "49: -7.4555e+01 -7.7416e+01  6e+00  9e-06  3e-07\n",
      "50: -7.4628e+01 -7.7129e+01  5e+00  7e-06  3e-07\n",
      "51: -7.4374e+01 -7.6831e+01  5e+00  6e-06  2e-07\n",
      "52: -7.4365e+01 -7.6367e+01  4e+00  5e-06  2e-07\n",
      "53: -7.4033e+01 -7.6037e+01  4e+00  3e-06  1e-07\n",
      "54: -7.3997e+01 -7.5915e+01  4e+00  3e-06  9e-08\n",
      "55: -7.3627e+01 -7.5629e+01  3e+00  2e-06  5e-08\n",
      "56: -7.3670e+01 -7.5506e+01  3e+00  1e-06  4e-08\n",
      "57: -7.3661e+01 -7.5447e+01  3e+00  1e-06  4e-08\n",
      "58: -7.3993e+01 -7.5166e+01  2e+00  7e-07  2e-08\n",
      "59: -7.3817e+01 -7.5013e+01  2e+00  4e-07  1e-08\n",
      "60: -7.4002e+01 -7.4933e+01  2e+00  3e-07  1e-08\n",
      "61: -7.4054e+01 -7.4849e+01  1e+00  1e-07  9e-09\n",
      "62: -7.4697e+01 -7.4769e+01  8e-02  1e-09  5e-09\n",
      "63: -7.4760e+01 -7.4763e+01  3e-03  5e-11  6e-09\n",
      "64: -7.4763e+01 -7.4763e+01  5e-05  8e-13  7e-09\n",
      "Optimal solution found.\n",
      "206 support vectors out of 3002 points\n",
      "304 out of 333 predictions correct\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Rank(A) < p or Rank([P; A; G]) < n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArithmeticError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\cvxopt\\misc.py\u001b[0m in \u001b[0;36mfactor\u001b[1;34m(W, H, Df)\u001b[0m\n\u001b[0;32m   1428\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m                     \u001b[0mlapack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1430\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mArithmeticError\u001b[0m: 2609",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mArithmeticError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\cvxopt\\coneprog.py\u001b[0m in \u001b[0;36mconeqp\u001b[1;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[0;32m   2064\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrti\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rti'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrti\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrti\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2065\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2066\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mArithmeticError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\cvxopt\\coneprog.py\u001b[0m in \u001b[0;36mkktsolver\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m   1980\u001b[0m          \u001b[1;32mdef\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1981\u001b[1;33m              \u001b[1;32mreturn\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\cvxopt\\misc.py\u001b[0m in \u001b[0;36mfactor\u001b[1;34m(W, H, Df)\u001b[0m\n\u001b[0;32m   1443\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1444\u001b[1;33m                     \u001b[0mlapack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1445\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mArithmeticError\u001b[0m: 2608",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-797eb3e21b5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m        \u001b[1;31m# plot_contour(X_train[y_train==1], X_train[y_train==-1], clf)\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtest_non_linear2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-64-797eb3e21b5a>\u001b[0m in \u001b[0;36mtest_non_linear2\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolynomial_kernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-577f5dab5dbf>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# solve QP problem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0msolution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcvxopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolvers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# Lagrange multipliers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\cvxopt\\coneprog.py\u001b[0m in \u001b[0;36mqp\u001b[1;34m(P, q, G, h, A, b, solver, kktsolver, initvals, **kwargs)\u001b[0m\n\u001b[0;32m   4485\u001b[0m             'residual as dual infeasibility certificate': dinfres}\n\u001b[0;32m   4486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4487\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconeqp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkktsolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\cvxopt\\coneprog.py\u001b[0m in \u001b[0;36mconeqp\u001b[1;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[0;32m   2065\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2066\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mArithmeticError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2067\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Rank(A) < p or Rank([P; A; G]) < n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Rank(A) < p or Rank([P; A; G]) < n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_non_linear2():\n",
    "    X1, y1, X2, y2 = gen_non_lin_separable_data()\n",
    "    \n",
    "    for i in range(1,10):\n",
    "\n",
    "\n",
    "        X_train, y_train, X_test, y_test = split_train(X1, y1, X2, y2,i)\n",
    "\n",
    "        def polynomial_kernel(x, y, p=i+1):\n",
    "            return (1 + np.dot(x, y)) ** p\n",
    "        clf = SVM(polynomial_kernel)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_predict = clf.predict(X_test)\n",
    "        correct = np.sum(y_predict == y_test)\n",
    "        print('{0} out of {1} predictions correct'.format(correct, len(y_predict)))\n",
    "\n",
    "       # plot_contour(X_train[y_train==1], X_train[y_train==-1], clf)\\\n",
    "\n",
    "test_non_linear2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when P is singular, an error is occur in CVXOPT.\n",
    "As the output of the kernel is so low at high degree, it can be occured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large Plotting\\ 2\\ principal\\ component\\ parts\\ and\\ margin(Polykernel).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$\\large Optimal\\ parameter\\ is\\ 4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0993e+02 -6.3507e+02  2e+04  9e+01  3e+00\n",
      " 1: -8.4098e+02 -2.0382e+03  1e+04  7e+01  2e+00\n",
      " 2: -2.1280e+03 -4.2305e+03  1e+04  6e+01  2e+00\n",
      " 3: -3.1546e+03 -5.3692e+03  1e+04  5e+01  2e+00\n",
      " 4: -5.1765e+03 -7.4599e+03  1e+04  4e+01  1e+00\n",
      " 5: -8.0625e+03 -1.0276e+04  1e+04  4e+01  1e+00\n",
      " 6: -1.0824e+04 -1.2953e+04  1e+04  4e+01  1e+00\n",
      " 7: -1.3656e+04 -1.5557e+04  1e+04  3e+01  1e+00\n",
      " 8: -1.9052e+04 -2.0189e+04  2e+04  3e+01  1e+00\n",
      " 9: -2.4565e+04 -2.5451e+04  2e+04  3e+01  1e+00\n",
      "10: -3.1892e+04 -3.1642e+04  2e+04  3e+01  1e+00\n",
      "11: -3.2130e+04 -3.0024e+04  2e+04  3e+01  9e-01\n",
      "12: -2.7959e+04 -2.2431e+04  3e+04  2e+01  8e-01\n",
      "13: -1.6130e+04 -8.6478e+03  3e+04  1e+01  5e-01\n",
      "14: -8.6633e+03 -3.4514e+03  2e+04  8e+00  3e-01\n",
      "15: -6.0328e+03 -2.2646e+03  2e+04  6e+00  2e-01\n",
      "16: -2.7718e+03 -1.1031e+03  8e+03  3e+00  1e-01\n",
      "17: -1.5034e+03 -7.8071e+02  6e+03  2e+00  6e-02\n",
      "18: -9.8643e+02 -6.3799e+02  4e+03  1e+00  4e-02\n",
      "19: -4.5460e+02 -4.6285e+02  2e+03  5e-01  2e-02\n",
      "20: -2.7792e+02 -3.7536e+02  2e+03  3e-01  1e-02\n",
      "21: -1.6857e+02 -2.8533e+02  9e+02  1e-01  5e-03\n",
      "22: -1.1418e+02 -2.5423e+02  7e+02  9e-02  3e-03\n",
      "23: -1.0284e+02 -2.0641e+02  4e+02  5e-02  2e-03\n",
      "24: -8.5016e+01 -1.7367e+02  3e+02  3e-02  9e-04\n",
      "25: -7.6584e+01 -1.5795e+02  2e+02  2e-02  6e-04\n",
      "26: -8.0441e+01 -1.3281e+02  2e+02  1e-02  3e-04\n",
      "27: -7.6295e+01 -1.1955e+02  1e+02  6e-03  2e-04\n",
      "28: -7.3471e+01 -1.1228e+02  1e+02  4e-03  1e-04\n",
      "29: -7.4712e+01 -1.0328e+02  7e+01  3e-03  9e-05\n",
      "30: -7.6748e+01 -9.5592e+01  5e+01  2e-03  6e-05\n",
      "31: -7.5661e+01 -9.2489e+01  4e+01  1e-03  4e-05\n",
      "32: -7.3042e+01 -9.0397e+01  4e+01  9e-04  3e-05\n",
      "33: -7.1746e+01 -8.9705e+01  4e+01  8e-04  3e-05\n",
      "34: -7.5213e+01 -8.5775e+01  2e+01  4e-04  1e-05\n",
      "35: -7.5075e+01 -8.4728e+01  2e+01  3e-04  9e-06\n",
      "36: -7.5757e+01 -8.3452e+01  1e+01  2e-04  5e-06\n",
      "37: -7.5813e+01 -8.3025e+01  1e+01  1e-04  4e-06\n",
      "38: -7.5272e+01 -8.2489e+01  1e+01  9e-05  3e-06\n",
      "39: -7.5255e+01 -8.1744e+01  1e+01  6e-05  2e-06\n",
      "40: -7.5338e+01 -8.1250e+01  9e+00  5e-05  2e-06\n",
      "41: -7.5452e+01 -8.0685e+01  9e+00  4e-05  1e-06\n",
      "42: -7.5203e+01 -8.0078e+01  8e+00  3e-05  1e-06\n",
      "43: -7.5153e+01 -7.9919e+01  8e+00  3e-05  1e-06\n",
      "44: -7.5189e+01 -7.9613e+01  8e+00  3e-05  1e-06\n",
      "45: -7.5350e+01 -7.9106e+01  7e+00  2e-05  8e-07\n",
      "46: -7.5292e+01 -7.8481e+01  7e+00  2e-05  6e-07\n",
      "47: -7.5379e+01 -7.8047e+01  6e+00  1e-05  5e-07\n",
      "48: -7.4654e+01 -7.7563e+01  6e+00  1e-05  3e-07\n",
      "49: -7.4555e+01 -7.7416e+01  6e+00  9e-06  3e-07\n",
      "50: -7.4628e+01 -7.7129e+01  5e+00  7e-06  3e-07\n",
      "51: -7.4374e+01 -7.6831e+01  5e+00  6e-06  2e-07\n",
      "52: -7.4365e+01 -7.6367e+01  4e+00  5e-06  2e-07\n",
      "53: -7.4033e+01 -7.6037e+01  4e+00  3e-06  1e-07\n",
      "54: -7.3997e+01 -7.5915e+01  4e+00  3e-06  9e-08\n",
      "55: -7.3627e+01 -7.5629e+01  3e+00  2e-06  5e-08\n",
      "56: -7.3670e+01 -7.5506e+01  3e+00  1e-06  4e-08\n",
      "57: -7.3661e+01 -7.5447e+01  3e+00  1e-06  4e-08\n",
      "58: -7.3993e+01 -7.5166e+01  2e+00  7e-07  2e-08\n",
      "59: -7.3817e+01 -7.5013e+01  2e+00  4e-07  1e-08\n",
      "60: -7.4002e+01 -7.4933e+01  2e+00  3e-07  1e-08\n",
      "61: -7.4054e+01 -7.4849e+01  1e+00  1e-07  9e-09\n",
      "62: -7.4697e+01 -7.4769e+01  8e-02  1e-09  5e-09\n",
      "63: -7.4760e+01 -7.4763e+01  3e-03  5e-11  6e-09\n",
      "64: -7.4763e+01 -7.4763e+01  5e-05  8e-13  7e-09\n",
      "Optimal solution found.\n",
      "206 support vectors out of 3002 points\n",
      "304 out of 333 predictions correct\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_non_linear2():\n",
    "    X1, y1, X2, y2 = gen_non_lin_separable_data()\n",
    "    \n",
    "    for i in range(3,4):\n",
    "\n",
    "\n",
    "        X_train, y_train, X_test, y_test = split_train(X1, y1, X2, y2,i)\n",
    "\n",
    "        def polynomial_kernel(x, y, p=i+1):\n",
    "            return (1 + np.dot(x, y)) ** p\n",
    "        clf = SVM(polynomial_kernel)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_predict = clf.predict(X_test)\n",
    "        correct = np.sum(y_predict == y_test)\n",
    "        print('{0} out of {1} predictions correct'.format(correct, len(y_predict)))\n",
    "\n",
    "        plot_contour(X_train[y_train==1], X_train[y_train==-1], clf)\n",
    "\n",
    "test_non_linear2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large sigmoid\\ kernel.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6308e+03 -4.6327e+03  3e+03  7e-13  3e+00\n",
      " 1: -3.0763e+03 -3.1330e+03  6e+01  5e-13  1e+00\n",
      " 2: -1.7136e+05 -1.7140e+05  4e+01  6e-11  1e+00\n",
      " 3: -6.1499e+06 -6.1516e+06  2e+03  3e-09  1e+00\n",
      " 4: -6.5241e+06 -6.5258e+06  2e+03  2e-09  1e+00\n",
      " 5: -3.5220e+07 -3.5227e+07  7e+03  2e-09  1e+00\n",
      " 6: -6.6807e+07 -6.6821e+07  1e+04  4e-08  1e+00\n",
      " 7: -3.7489e+08 -3.7497e+08  8e+04  3e-07  1e+00\n",
      " 8: -4.7712e+08 -4.7722e+08  1e+05  1e-07  1e+00\n",
      " 9: -9.8653e+08 -9.8673e+08  2e+05  6e-08  1e+00\n",
      "10: -3.4519e+09 -3.4526e+09  7e+05  6e-08  1e+00\n",
      "11: -3.7484e+09 -3.7492e+09  8e+05  1e-06  1e+00\n",
      "12: -8.7620e+09 -8.7638e+09  2e+06  5e-06  1e+00\n",
      "13: -8.9256e+09 -8.9275e+09  2e+06  1e-07  1e+00\n",
      "14: -2.6584e+10 -2.6589e+10  5e+06  1e-05  1e+00\n",
      "15: -6.1587e+10 -6.1600e+10  1e+07  1e-05  1e+00\n",
      "16: -1.0280e+11 -1.0282e+11  2e+07  8e-06  1e+00\n",
      "17: -1.2948e+11 -1.2951e+11  3e+07  6e-05  1e+00\n",
      "18: -2.3689e+11 -2.3694e+11  5e+07  1e-04  1e+00\n",
      "19: -4.4292e+11 -4.4301e+11  9e+07  1e-04  1e+00\n",
      "20: -7.7107e+11 -7.7123e+11  2e+08  1e-04  1e+00\n",
      "21: -1.2223e+12 -1.2225e+12  2e+08  4e-04  1e+00\n",
      "22: -1.4797e+12 -1.4800e+12  3e+08  1e-04  1e+00\n",
      "23: -2.1399e+12 -2.1403e+12  4e+08  1e-03  1e+00\n",
      "24: -3.2329e+12 -3.2335e+12  6e+08  4e-04  1e+00\n",
      "25: -4.0929e+12 -4.0936e+12  7e+08  3e-04  1e+00\n",
      "26: -5.9142e+12 -5.9151e+12  9e+08  5e-04  1e+00\n",
      "27: -6.7287e+12 -6.7296e+12  9e+08  2e-03  1e+00\n",
      "Terminated (singular KKT matrix).\n",
      "5561 support vectors out of 5561 points\n",
      "568 out of 617 predictions correct\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6308e+03 -4.6327e+03  3e+03  1e-11  3e+00\n",
      " 1: -3.0763e+03 -3.1330e+03  6e+01  4e-12  1e+00\n",
      " 2: -1.7153e+05 -1.7156e+05  3e+01  6e-11  1e+00\n",
      " 3: -9.2289e+08 -9.2289e+08  2e+03  1e-06  1e+00\n",
      " 4: -1.7651e+13 -1.7651e+13  3e+07  4e-03  1e+00\n",
      "Terminated (singular KKT matrix).\n",
      "5561 support vectors out of 5561 points\n",
      "568 out of 617 predictions correct\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6308e+03 -4.6327e+03  3e+03  1e-11  3e+00\n",
      " 1: -3.0763e+03 -3.1330e+03  6e+01  4e-12  1e+00\n",
      " 2: -1.7153e+05 -1.7156e+05  3e+01  6e-11  1e+00\n",
      " 3: -9.2289e+08 -9.2289e+08  2e+03  1e-06  1e+00\n",
      " 4: -1.7651e+13 -1.7651e+13  3e+07  4e-03  1e+00\n",
      "Terminated (singular KKT matrix).\n",
      "5561 support vectors out of 5561 points\n",
      "568 out of 617 predictions correct\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6308e+03 -4.6327e+03  3e+03  1e-11  3e+00\n",
      " 1: -3.0763e+03 -3.1330e+03  6e+01  4e-12  1e+00\n",
      " 2: -1.7153e+05 -1.7156e+05  3e+01  6e-11  1e+00\n",
      " 3: -9.2289e+08 -9.2289e+08  2e+03  1e-06  1e+00\n",
      " 4: -1.7651e+13 -1.7651e+13  3e+07  4e-03  1e+00\n",
      "Terminated (singular KKT matrix).\n",
      "5561 support vectors out of 5561 points\n",
      "568 out of 617 predictions correct\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6308e+03 -4.6327e+03  3e+03  1e-11  3e+00\n",
      " 1: -3.0763e+03 -3.1330e+03  6e+01  4e-12  1e+00\n",
      " 2: -1.7153e+05 -1.7156e+05  3e+01  6e-11  1e+00\n",
      " 3: -9.2289e+08 -9.2289e+08  2e+03  1e-06  1e+00\n",
      " 4: -1.7651e+13 -1.7651e+13  3e+07  4e-03  1e+00\n",
      "Terminated (singular KKT matrix).\n",
      "5561 support vectors out of 5561 points\n",
      "568 out of 617 predictions correct\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6308e+03 -4.6327e+03  3e+03  1e-11  3e+00\n",
      " 1: -3.0763e+03 -3.1330e+03  6e+01  4e-12  1e+00\n",
      " 2: -1.7153e+05 -1.7156e+05  3e+01  6e-11  1e+00\n",
      " 3: -9.2289e+08 -9.2289e+08  2e+03  1e-06  1e+00\n",
      " 4: -1.7651e+13 -1.7651e+13  3e+07  4e-03  1e+00\n",
      "Terminated (singular KKT matrix).\n",
      "5561 support vectors out of 5561 points\n",
      "568 out of 617 predictions correct\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6308e+03 -4.6327e+03  3e+03  1e-11  3e+00\n",
      " 1: -3.0763e+03 -3.1330e+03  6e+01  4e-12  1e+00\n",
      " 2: -1.7153e+05 -1.7156e+05  3e+01  6e-11  1e+00\n",
      " 3: -9.2289e+08 -9.2289e+08  2e+03  1e-06  1e+00\n",
      " 4: -1.7651e+13 -1.7651e+13  3e+07  4e-03  1e+00\n",
      "Terminated (singular KKT matrix).\n",
      "5561 support vectors out of 5561 points\n",
      "568 out of 617 predictions correct\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6308e+03 -4.6327e+03  3e+03  1e-11  3e+00\n",
      " 1: -3.0763e+03 -3.1330e+03  6e+01  4e-12  1e+00\n",
      " 2: -1.7153e+05 -1.7156e+05  3e+01  6e-11  1e+00\n",
      " 3: -9.2289e+08 -9.2289e+08  2e+03  1e-06  1e+00\n",
      " 4: -1.7651e+13 -1.7651e+13  3e+07  4e-03  1e+00\n",
      "Terminated (singular KKT matrix).\n",
      "5561 support vectors out of 5561 points\n",
      "568 out of 617 predictions correct\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6308e+03 -4.6327e+03  3e+03  1e-11  3e+00\n",
      " 1: -3.0763e+03 -3.1330e+03  6e+01  4e-12  1e+00\n",
      " 2: -1.7153e+05 -1.7156e+05  3e+01  6e-11  1e+00\n",
      " 3: -9.2289e+08 -9.2289e+08  2e+03  1e-06  1e+00\n",
      " 4: -1.7651e+13 -1.7651e+13  3e+07  4e-03  1e+00\n",
      "Terminated (singular KKT matrix).\n",
      "5561 support vectors out of 5561 points\n",
      "568 out of 617 predictions correct\n"
     ]
    }
   ],
   "source": [
    "def test_non_linear3():\n",
    "    X1, y1, X2, y2 = gen_non_lin_separable_data()\n",
    "    \n",
    "    \n",
    "    for i in range(1,10):\n",
    "        X_train, y_train, X_test, y_test = split_train(X1, y1, X2, y2,i)\n",
    "\n",
    "\n",
    "        def sigmoid_kernel(x1,x2,k=0.0001,theta=(-10)*i):\n",
    "            return np.tanh(k*np.dot(x1,x2)+theta) \n",
    "\n",
    "        clf = SVM(sigmoid_kernel)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_predict = clf.predict(X_test)\n",
    "        correct = np.sum(y_predict == y_test)\n",
    "        print('{0} out of {1} predictions correct'.format(correct, len(y_predict)))\n",
    "\n",
    "    #plot_contour(X_train[y_train==1], X_train[y_train==-1], clf)\n",
    "    \n",
    "test_non_linear3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I conclude Sigmoid kernels are not Inadequate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
